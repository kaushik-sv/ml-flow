{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d44c025d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "512251c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7c07709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    os.makedirs(housing_path, exist_ok=True)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b38c96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7734e23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac7f4cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = load_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "004b45d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room = True): # no *args or **kargs\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "    def transform(self, X):\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, households_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household,\n",
    "                         bedrooms_per_room]\n",
    "\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa1beb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('attribs_adder', CombinedAttributesAdder()),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d294bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    data[\"income_cat\"] = pd.cut(data[\"median_income\"],\n",
    "                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
    "                               labels=[1, 2, 3, 4, 5])\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    for train_index, test_index in split.split(data, data[\"income_cat\"]):\n",
    "        strat_train_set = data.loc[train_index]\n",
    "        strat_test_set = data.loc[test_index]\n",
    "    for set_ in (strat_train_set, strat_test_set):\n",
    "        set_.drop(\"income_cat\", axis=1, inplace=True)\n",
    "    data = strat_train_set.drop(\"median_house_value\", axis=1)\n",
    "    data_labels = strat_train_set[\"median_house_value\"].copy()\n",
    "    data_num = data.drop(\"ocean_proximity\", axis=1)\n",
    "    data_num_tr = num_pipeline.fit_transform(data_num)\n",
    "    num_attribs = list(data_num)\n",
    "    cat_attribs = [\"ocean_proximity\"]\n",
    "    full_pipeline = ColumnTransformer([\n",
    "            (\"num\", num_pipeline, num_attribs),\n",
    "            (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "        ])\n",
    "    data_prepared = full_pipeline.fit_transform(data)\n",
    "    return data_prepared, data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "014a817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data_prepared, data_labels):\n",
    "    lin_reg = LinearRegression()\n",
    "    lin_reg.fit(data_prepared, data_labels)\n",
    "    lin_scores = cross_val_score(lin_reg, data_prepared, data_labels,\n",
    "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "    return lin_rmse_scores, lin_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "630acc0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://localhost:5000'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote_server_uri = \"http://localhost:5000\"\n",
    "mlflow.set_tracking_uri(remote_server_uri)\n",
    "mlflow.get_tracking_uri()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3b99673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='./mlruns/2', experiment_id='2', lifecycle_stage='active', name='House_price_predictions', tags={}>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_name = \"House_price_predictions\"\n",
    "mlflow.set_experiment(exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea04eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/08/09 14:38:33 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh()\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial warning can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|none|n|0: for no warning or exception\n",
      "    - warn|w|warning|1: for a printed warning\n",
      "    - error|e|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n",
      "C:\\Users\\kaushik.singha\\Anaconda3\\lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name='PARENT_RUN') as parent_run:\n",
    "    mlflow.log_param(\"parent\", \"yes\")\n",
    "    with mlflow.start_run(run_name='DATA_PREPARATION', nested=True) as data_preparation:\n",
    "        housing_prepared, housing_labels = prepare_data(housing)\n",
    "        mlflow.log_params({\"Scaler\":\"Standard Scaler\",\"Imputer\":\"Simple Imputer\",\"Categorical Encoder\":\"One Hot Encoder\"})\n",
    "        mlflow.log_artifact(HOUSING_PATH)\n",
    "    with mlflow.start_run(run_name='MODEL_TRAINING', nested=True) as model_training:\n",
    "        model_scores, model = train_model(housing_prepared, housing_labels)\n",
    "        mlflow.log_metrics({\"Mean\":model_scores.mean(),\"Standard_deviation\":model_scores.std()})\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "        print(\"Save to {}\".format(mlflow.get_artifact_uri()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b394211",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
